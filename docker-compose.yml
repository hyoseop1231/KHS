version: '3.8'

services:
  redis:
    image: redis:7-alpine
    container_name: rag_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped

  ollama:
    image: ollama/ollama:0.2.0 # 설계서 버전 명시
    container_name: rag_ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    # tty: true # 백그라운드 실행 및 모델 pull 등을 위해 필요할 수 있음
    # GPU 사용 안 할 경우 아래 deploy 부분은 주석 처리 또는 제거
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: 1 # 사용할 GPU 수
    #           capabilities: [gpu]
    restart: unless-stopped

  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    container_name: rag_backend
    ports:
      - "8000:8000"
    volumes:
      - ./backend/app:/app # backend/app 폴더를 컨테이너 /app에 마운트 (코드 변경 실시간 반영)
      - ./backend/faiss_data:/faiss_data # FAISS 인덱스 및 TinyDB 데이터 영구 저장
      - ./backend/uploads:/app/uploads # 업로드된 파일 접근 (Dockerfile의 COPY와 일관성)
    environment:
      - PYTHONUNBUFFERED=1
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OLLAMA_BASE_URL=http://ollama:11434 # Ollama 서비스 접근 주소
      # - PYTHONPATH=/app # 필요시 추가
    depends_on:
      - redis
      - ollama
    restart: unless-stopped

  worker:
    build:
      context: .
      dockerfile: backend/Dockerfile # 동일한 백엔드 이미지 사용
    container_name: rag_worker
    command: celery -A app.tasks:celery_app worker -l info -Q cel_queue -c 4 --prefetch-multiplier=1
    volumes:
      - ./backend/app:/app # 코드 변경 실시간 반영
      - ./backend/faiss_data:/faiss_data # FAISS 인덱스 및 TinyDB 데이터 접근
      - ./backend/uploads:/app/uploads # 처리할 파일 접근
    environment:
      - PYTHONUNBUFFERED=1
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - OLLAMA_BASE_URL=http://ollama:11434
      # - PYTHONPATH=/app
    depends_on:
      - redis
      - ollama # Ollama 모델을 worker에서도 사용할 경우
      - backend # backend 서비스의 초기화(모델 로딩 등)가 필요하다면
    restart: unless-stopped

  frontend:
    build:
      context: .
      dockerfile: frontend/Dockerfile
    container_name: rag_frontend
    ports:
      - "3000:80" # 외부 3000 포트 -> 컨테이너 80 포트 (Nginx)
    depends_on:
      - backend
    restart: unless-stopped

volumes:
  redis_data:
  ollama_data: # ollama 서비스의 볼륨과 이름 일치
  # faiss_data: # backend 서비스에서 직접 경로 매핑 사용
  # uploads_data: # backend 서비스에서 직접 경로 매핑 사용
